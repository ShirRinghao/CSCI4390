# Load package
import sys
import numpy as np
import pandas as pd
import statistics
import random
from numpy import linalg as LA
import matplotlib.pyplot as plt

# written according to pseudocode from the given textbook
def part1_pca(D, alpha):
    # Calculate center matrix, covariance, variance, and eigenvector
    centerMatrix = D - np.mean(D, 0)
    covariance = np.cov(np.transpose(centerMatrix))
    variance = np.trace(covariance)
    value, eigenvector = LA.eig(covariance)

    # Loop through to find the minimum dimension required
    sumValue = 0
    d_required = 0
    for i in range(0,len(value) +1):
        if (alpha <= (sumValue / variance)):
            d_required = i
            break
        sumValue = sumValue + value[i]

    # Calculate MSE and matrix of eigenvector
    mse = variance - sum(value[0:3])
    u1 = eigenvector[0:2] @ centerMatrix.transpose()
    print("We need {:} dimensions to capture alpha = {:.3f} fraction of total variance.\nMean Squared Error is {:5f}.".format(d_required, alpha, mse))

    # Plot the graph
    plt.figure(figsize=(5, 5))
    plt.scatter(u1[0],u1[1])
    plt.show()


if __name__ == '__main__':
    # Read file and format the data using numpy
    file = open(sys.argv[1], 'r')
    alpha = float(sys.argv[2])
    data = pd.read_csv(file, delimiter=',', skiprows=1, usecols=range(1, 28), header=None).to_numpy()

    # Part 1, PCA function
    part1_pca(data, 0.975)